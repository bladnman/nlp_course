{"cells":[{"cell_type":"markdown","metadata":{"id":"3KSnx8nHRe9W"},"source":["___\n","\n","<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n","___"]},{"cell_type":"markdown","metadata":{"id":"MVd1KvUdRe9b"},"source":["# Sentence Segmentation\n","In **spaCy Basics** we saw briefly how Doc objects are divided into sentences. In this section we'll learn how sentence segmentation works, and how to set our own segmentation rules."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y3ueC-xpRe9d"},"outputs":[],"source":["# Perform standard imports\n","import spacy\n","nlp = spacy.load('en_core_web_sm')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8FDuwkBHRe9f","outputId":"fe9c0843-2f94-420a-8a9b-c3f2731757a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["This is the first sentence.\n","This is another sentence.\n","This is the last sentence.\n"]}],"source":["# From Spacy Basics:\n","doc = nlp(u'This is the first sentence. This is another sentence. This is the last sentence.')\n","\n","for sent in doc.sents:\n","    print(sent)"]},{"cell_type":"markdown","metadata":{"id":"Mco3ce4cRe9h"},"source":["### `Doc.sents` is a generator\n","It is important to note that `doc.sents` is a *generator*. That is, a Doc is not segmented until `doc.sents` is called. This means that, where you could print the second Doc token with `print(doc[1])`, you can't call the \"second Doc sentence\" with `print(doc.sents[1])`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ZYgTX5GRe9h","outputId":"cef22f0e-d1e8-4649-b8b4-56becb19dd1e"},"outputs":[{"name":"stdout","output_type":"stream","text":["is\n"]}],"source":["print(doc[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jtMgnuhMRe9i","outputId":"529821af-5ac9-47d0-b8e2-41b4ba0b28c1"},"outputs":[{"ename":"TypeError","evalue":"'generator' object is not subscriptable","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-4-2bc012eee1da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"]}],"source":["print(doc.sents[1])"]},{"cell_type":"markdown","metadata":{"id":"7lNfWJTFRe9j"},"source":["However, you *can* build a sentence collection by running `doc.sents` and saving the result to a list:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Puz_RK0FRe9k","outputId":"58c96314-3cbd-401c-eb1d-34f48d0981b7"},"outputs":[{"data":{"text/plain":["[This is the first sentence.,\n"," This is another sentence.,\n"," This is the last sentence.]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["doc_sents = [sent for sent in doc.sents]\n","doc_sents"]},{"cell_type":"markdown","metadata":{"id":"FXPCkf4HRe9l"},"source":["<font color=green>**NOTE**: `list(doc.sents)` also works. We show a list comprehension as it allows you to pass in conditionals.</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6u5xGJupRe9m","outputId":"205393ed-8481-472e-8e58-a9833c3c0409"},"outputs":[{"name":"stdout","output_type":"stream","text":["This is another sentence.\n"]}],"source":["# Now you can access individual sentences:\n","print(doc_sents[1])"]},{"cell_type":"markdown","metadata":{"id":"nCbUoZsmRe9m"},"source":["### `sents` are Spans\n","At first glance it looks like each `sent` contains text from the original Doc object. In fact they're just Spans with start and end token pointers."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HQKOUSlbRe9n","outputId":"78114a15-7a59-49e9-bb76-eb288383cf79"},"outputs":[{"data":{"text/plain":["spacy.tokens.span.Span"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["type(doc_sents[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qA50ZT-sRe9n","outputId":"a1cd8227-6066-4900-edbd-95412bc293f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["6 11\n"]}],"source":["print(doc_sents[1].start, doc_sents[1].end)"]},{"cell_type":"markdown","metadata":{"id":"NovGmJhhRe9o"},"source":["## Adding Rules\n","spaCy's built-in `sentencizer` relies on the dependency parse and end-of-sentence punctuation to determine segmentation rules. We can add rules of our own, but they have to be added *before* the creation of the Doc object, as that is where the parsing of segment start tokens happens:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M1DPDI3wRe9o","outputId":"f8967511-87b4-4348-a889-279e9ffd8bd6"},"outputs":[{"name":"stdout","output_type":"stream","text":["None  This\n","None  is\n","None  a\n","None  sentence\n","None  .\n","True  This\n","None  is\n","None  a\n","None  sentence\n","None  .\n","True  This\n","None  is\n","None  a\n","None  sentence\n","None  .\n"]}],"source":["# Parsing the segmentation start tokens happens during the nlp pipeline\n","doc2 = nlp(u'This is a sentence. This is a sentence. This is a sentence.')\n","\n","for token in doc2:\n","    print(token.is_sent_start, ' '+token.text)"]},{"cell_type":"markdown","metadata":{"id":"VCpgvcM3Re9p"},"source":["<font color=green>Notice we haven't run `doc2.sents`, and yet `token.is_sent_start` was set to True on two tokens in the Doc.</font>"]},{"cell_type":"markdown","metadata":{"id":"k_rK15EgRe9p"},"source":["Let's add a semicolon to our existing segmentation rules. That is, whenever the sentencizer encounters a semicolon, the next token should start a new segment."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ojdEAivBRe9q","outputId":"939b8c1b-fb64-4df7-99d2-1b49c5aa05eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["\"Management is doing things right; leadership is doing the right things.\"\n","-Peter Drucker\n"]}],"source":["# SPACY'S DEFAULT BEHAVIOR\n","doc3 = nlp(u'\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n","\n","for sent in doc3.sents:\n","    print(sent)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IV9DFRwpRe9r","outputId":"85c16189-68c7-4af2-b1fc-a2da7b47ba48"},"outputs":[{"data":{"text/plain":["['tagger', 'set_custom_boundaries', 'parser', 'ner']"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# ADD A NEW RULE TO THE PIPELINE\n","def set_custom_boundaries(doc):\n","    for token in doc[:-1]:\n","        if token.text == ';':\n","            doc[token.i+1].is_sent_start = True\n","    return doc\n","\n","nlp.add_pipe(set_custom_boundaries, before='parser')\n","\n","nlp.pipe_names"]},{"cell_type":"markdown","metadata":{"id":"HIqrPHRrRe9r"},"source":["<font color=green>The new rule has to run before the document is parsed. Here we can either pass the argument `before='parser'` or `first=True`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3oEFe784Re9s","outputId":"fc6ad1d0-4f9a-4b3f-9176-73091c3f955f"},"outputs":[{"name":"stdout","output_type":"stream","text":["\"Management is doing things right;\n","leadership is doing the right things.\"\n","-Peter Drucker\n"]}],"source":["# Re-run the Doc object creation:\n","doc4 = nlp(u'\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n","\n","for sent in doc4.sents:\n","    print(sent)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HMZPAhh7Re9s","outputId":"ef1972b0-953d-44b0-f8f8-e8000ba554e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["\"Management is doing things right; leadership is doing the right things.\"\n","-Peter Drucker\n"]}],"source":["# And yet the new rule doesn't apply to the older Doc object:\n","for sent in doc3.sents:\n","    print(sent)"]},{"cell_type":"markdown","metadata":{"id":"TJ9KT9SkRe9t"},"source":["### Why not change the token directly?\n","Why not simply set the `.is_sent_start` value to True on existing tokens?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y1vcp47CRe9t","outputId":"7503cbaa-f50e-4461-dc78-7108216a613b"},"outputs":[{"data":{"text/plain":["leadership"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Find the token we want to change:\n","doc3[7]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qs4i_DYVRe9t","outputId":"0d9a0a2a-108a-4864-adfe-bba36a128469"},"outputs":[{"ename":"ValueError","evalue":"[E043] Refusing to write to token.sent_start if its document is parsed, because this may cause inconsistent state.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m<ipython-input-5-bcec3fe6a9a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Try to change the .is_sent_start attribute:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdoc3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sent_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mtoken.pyx\u001b[0m in \u001b[0;36mspacy.tokens.token.Token.is_sent_start.__set__\u001b[1;34m()\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: [E043] Refusing to write to token.sent_start if its document is parsed, because this may cause inconsistent state."]}],"source":["# Try to change the .is_sent_start attribute:\n","doc3[7].is_sent_start = True"]},{"cell_type":"markdown","metadata":{"id":"nJvIq8XTRe9t"},"source":["<font color=green>spaCy refuses to change the tag after the document is parsed to prevent inconsistencies in the data.</font>"]},{"cell_type":"markdown","metadata":{"id":"58oTAs8RRe9u"},"source":["## Changing the Rules\n","In some cases we want to *replace* spaCy's default sentencizer with our own set of rules. In this section we'll see how the default sentencizer breaks on periods. We'll then replace this behavior with a sentencizer that breaks on linebreaks."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n5s1Uo71Re9u","outputId":"a11fef52-520c-4b5c-d9f8-a884734afcbb"},"outputs":[{"name":"stdout","output_type":"stream","text":["['This', 'is', 'a', 'sentence', '.']\n","['This', 'is', 'another', '.', '\\n\\n']\n","['This', 'is', 'a', '\\n', 'third', 'sentence', '.']\n"]}],"source":["nlp = spacy.load('en_core_web_sm')  # reset to the original\n","\n","mystring = u\"This is a sentence. This is another.\\n\\nThis is a \\nthird sentence.\"\n","\n","# SPACY DEFAULT BEHAVIOR:\n","doc = nlp(mystring)\n","\n","for sent in doc.sents:\n","    print([token.text for token in sent])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Rq2l2bDRe9u"},"outputs":[],"source":["# CHANGING THE RULES\n","from spacy.pipeline import SentenceSegmenter\n","\n","def split_on_newlines(doc):\n","    start = 0\n","    seen_newline = False\n","    for word in doc:\n","        if seen_newline:\n","            yield doc[start:word.i]\n","            start = word.i\n","            seen_newline = False\n","        elif word.text.startswith('\\n'): # handles multiple occurrences\n","            seen_newline = True\n","    yield doc[start:]      # handles the last group of tokens\n","\n","\n","sbd = SentenceSegmenter(nlp.vocab, strategy=split_on_newlines)\n","nlp.add_pipe(sbd)"]},{"cell_type":"markdown","metadata":{"id":"0hCnXhuJRe9v"},"source":["<font color=green>While the function `split_on_newlines` can be named anything we want, it's important to use the name `sbd` for the SentenceSegmenter.</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ahSLnukPRe9v","outputId":"33fe1614-6a3e-4817-9473-ec5b677a69b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["['This', 'is', 'a', 'sentence', '.', 'This', 'is', 'another', '.', '\\n\\n']\n","['This', 'is', 'a', '\\n']\n","['third', 'sentence', '.']\n"]}],"source":["doc = nlp(mystring)\n","for sent in doc.sents:\n","    print([token.text for token in sent])"]},{"cell_type":"markdown","metadata":{"id":"Xu66oSToRe9v"},"source":["<font color=green>Here we see that periods no longer affect segmentation, only linebreaks do. This would be appropriate when working with a long list of tweets, for instance.</font>\n","## Next Up: POS Assessment"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"name":"04-Sentence-Segmentation.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}